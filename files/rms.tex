%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% Appendix file included in main project file using \input{}
%
% Assumes that LaTeX2e macros and packages defined in cg_comp.sty are
%   available
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

 \section{Compensation by Minimizing RMS Error\label{app:rms}}

The root-mean-square (RMS) frequency error (in cents) averaged over the frets $n \in \{1, n_\text{max}\}$ \emph{of a particular string} is given by
 \begin{equation}\label{eqn:rms_def}
\overline{\Delta \nu}_\text{rms} \equiv \sqrt{\frac{\sum_{n = 1}^{n_\text{max}} \Delta \nu_n^2}{n_\text{max}}}\, ,
 \end{equation}
where $\Delta \nu_n$ is given by \eqn{error_tot}. Here we will vary both $\Delta S$ and $\Delta N$ to minimize $\overline{\Delta \nu}_\text{rms}$. In this case, it is sufficient to minimize the quantity
 \begin{equation}\label{eqn:chi2_def}
\chi^2 = \sum_{n = 1}^{n_\text{max}} \left[\frac{\ln(2)}{1200}\, \Delta \nu_n\right]^2
 \end{equation}
such that the gradient of $\chi^2$ with respect to $\Delta S$ and $\Delta N$ vanishes. The components of this gradient are
 \begin{subequations}\label{chi2_grad}
 \begin{align}
\frac{\partial}{\partial \Delta S}\, \chi^2 &= -\frac{2}{X_0}\, \sum_n (\gamma_n - 1)\left[ (\gamma_n - 1) \left(B_0 - \frac{\Delta S}{X_0}\right) + \frac{\Delta N}{X_0} + \frac{\kappa}{2}\, Q_n \right]\, , \nd \\
\frac{\partial}{\partial \Delta N}\, \chi^2 &= \frac{2}{X_0}\, \sum_n \left[ (\gamma_n - 1) \left(B_0 - \frac{\Delta S}{X_0}\right) + \frac{\Delta N}{X_0} + \frac{\kappa}{2}\, Q_n \right]\, .
 \end{align}
 \end{subequations}
Setting both of these expressions to zero, we can rewrite them as the matrix equation
 \begin{equation} \label{eqn:rms_mat}
\begin{bmatrix}
  \sigma_2 & -\sigma_1 \\
  \sigma_1 & -\sigma_0
\end{bmatrix}\,
\begin{bmatrix}
  \Delta S \\
  \Delta N
\end{bmatrix} = X_0
\begin{bmatrix}
  \sigma_2\, B_0 +  \half\, \kappa\, \overline{Q}_1 \\
  \sigma_1\, B_0 +  \half\, \kappa\, \overline{Q}_0
\end{bmatrix}\, ,
 \end{equation}
where
 \begin{align}
\sigma_k &\equiv \sum_{n = 1}^{n_\text{max}} \left(\gamma_n - 1\right)^k\, , \nd \\
\overline{Q}_k &\equiv \sum_{n = 1}^{n_\text{max}} \left(\gamma_n - 1\right)^k\, Q_n\, .
 \end{align}
We note that
\begin{subequations}
  \begin{align}
    \sigma_0 &= n_\text{max}\, ,\\
    \sigma_1 &= \frac{\gamma_1 \left(\gamma_{n_\text{max}} - 1\right)}{\gamma_1 - 1} - \sigma_0
  \end{align}
\end{subequations}

 \Eqn{rms_mat} has the straightforward analytic solution
\begin{equation}
  \begin{bmatrix}
    \Delta S \\
    \Delta N
  \end{bmatrix} = \frac{X_0}{\sigma_1^2 - \sigma_0\, \sigma_2}\,
  \begin{bmatrix}
    -\sigma_0 & \sigma_1 \\
    -\sigma_1 & \sigma_2
  \end{bmatrix}\,
  \begin{bmatrix}
    \sigma_2\, B_0 + \half\, \kappa\, \overline{Q}_1 \\
    \sigma_1\, B_0 + \half\, \kappa\, \overline{Q}_0
  \end{bmatrix}\, ,
\end{equation}
or
\begin{subequations} \label{eqn:rms_sol}
  \begin{align}
    \label{eqn:rms_sol_ds} \Delta S &= B_0\, X_0 + \frac{\kappa\, X_0}{2 \left(\sigma_1^2 - \sigma_0\, \sigma_2\right)}\, \left( \sigma_1\, \overline{Q}_0 - \sigma_0\, \overline{Q}_1 \right)\, , \nd \\
    \label{eqn:rms_sol_dn} \Delta N &= \frac{\kappa\, X_0}{2 \left(\sigma_1^2 - \sigma_0\, \sigma_2\right)}\, \left( \sigma_2\, \overline{Q}_0 - \sigma_1\, \overline{Q}_1 \right)\, .
  \end{align}
\end{subequations}
For completeness, the corresponding solution when the quadratic stiffness term is included is given by
 \begin{equation}\label{eqn:rms_sol_quad}
\begin{bmatrix}
  \Delta S \\
  \Delta N
\end{bmatrix} = \frac{X_0}{\sigma_1^2 - \sigma_0\, \sigma_2}\,
\begin{bmatrix}
  -\sigma_0 & \sigma_1 \\
  -\sigma_1 & \sigma_2
\end{bmatrix}\,
\begin{bmatrix}
  \sigma_2\, B_0 + \half \left(1 + \pi^2\right) \left(2 \sigma_2 + \sigma_3\right) B_0^2 + \half\, \kappa\, \overline{Q}_1 \\
  \sigma_1\, B_0 + \half \left(1 + \pi^2\right) \left(2 \sigma_1 + \sigma_2\right) B_0^2 + \half\, \kappa\, \overline{Q}_0
\end{bmatrix}\, .
 \end{equation}

The corresponding Hessian matrix for this problem is
 \begin{equation}
H = \begin{bmatrix}
      \frac{\partial^2 \chi^2}{\partial \Delta S^2} & \frac{\partial^2 \chi^2}{\partial \Delta N\, \partial \Delta S} \\
      \frac{\partial^2 \chi^2}{\partial \Delta S\, \partial \Delta N} & \frac{\partial^2 \chi^2}{\partial \Delta N^2}
    \end{bmatrix}
  = \frac{2}{X_0^2} \begin{bmatrix}
      \sigma_2 & -\sigma_1 \\
      -\sigma_1 & \sigma_0
    \end{bmatrix}\, .
 \end{equation}
The Hessian is positive definite if and only if all of its eigenvalues are positive, and in the case of a $2 \times 2$ real matrix, this holds when the determinant is greater than zero. It is easy to verify numerically (and with some effort algebraically) that $\Det(H) > 0$ for $n_\text{max} > 1$. Therefore, the solution for $\Delta S$ and $\Delta N$ given by \eqn{rms_sol} minimizes the RMS frequency error.

The setback solution given by \eqn{rms_sol} is valid for a single string, and results like those shown in \tbl{ej45_setbacks} and \fig{shift_alhambra8p_ej45_full} assume that the guitar is built such that each string --- from a particular set of strings --- has a unique saddle and nut setback. Suppose that we'd prefer to engineer a guitar with single, uniform values of both $\Delta S$ and $\Delta N$ that provide reasonable compensation across an entire string set (or an ensemble of strings from a variety of manufacturers). In this case, \eqn{rms_def} becomes
 \begin{equation}\label{eqn:rms_def_m}
\overline{\Delta \nu}_\text{rms} \equiv \sqrt{\frac{\sum_{m = 1}^{m_\text{max}} \sum_{n = 1}^{n_\text{max}} \left[\Delta \nu^{(m)}_{n}\right]^2}{m_\text{max}\, n_\text{max}}}\, ,
 \end{equation}
where $m$ labels the strings in the set, and \eqn{error_tot} has been updated to become
 \begin{equation}\label{eqn:error_tot_m}
\Delta \nu^{(m)}_n \approx \frac{1200}{\ln(2)}\, \left\{ \left(\gamma_n - 1\right) \left[B_0^{(m)} - \frac{\Delta S}{X_0}\right] + \frac{\Delta N}{X_0} + \half\, \kappa^{(m)}\, Q_n \right\}\, .
 \end{equation}
If we rigorously follow the same approach that we used to arrive at \eqn{rms_sol}, in the multi-string case we obtain
 \begin{equation}\label{eqn:rms_sol_multi}
\begin{bmatrix}
  \Delta S \\
  \Delta N
\end{bmatrix} = \frac{1}{m_\text{max}}\, 
\begin{bmatrix}
  \sum_{m = 1}^{m_\text{max}} \Delta S^{(m)} \\
  \sum_{m = 1}^{m_\text{max}} \Delta N^{(m)}
\end{bmatrix}\, ,
 \end{equation}
where
 \begin{equation}\label{eqn:rms_sol_uni}
\begin{bmatrix}
  \Delta S^{(m)} \\
  \Delta N^{(m)}
\end{bmatrix} = \frac{X_0}{\sigma_1^2 - \sigma_0\, \sigma_2}\,
\begin{bmatrix}
  -\sigma_0 & \sigma_1 \\
  -\sigma_1 & \sigma_2
\end{bmatrix}\,
\begin{bmatrix}
  \sigma_2\, B_0^{(m)} + \half\, \kappa^{(m)}\, \overline{Q}_1 \\
  \sigma_1\, B_0^{(m)} + \half\, \kappa^{(m)}\, \overline{Q}_0
\end{bmatrix}\, .
 \end{equation}
In other words, we can find the optimum values for both $\Delta S$ and $\Delta N$ simply by averaging the corresponding setbacks over a commercially interesting collection of string sets. 